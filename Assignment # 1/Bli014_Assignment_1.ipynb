{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1 - Splitting the data \n",
    "# Task 3 - Selectings the metadata 'text' and 'airline_sentiment'\n",
    "\n",
    "data = pd.read_csv('tweets.csv')\n",
    "data_x = data[['text', 'airline_sentiment']]\n",
    "x_train, x_test = train_test_split(data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2 - Creating a vocabulary using vectorizer. \n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "vector_test = CountVectorizer(stop_words='english')\n",
    "vectorizer.fit(x_train.text)\n",
    "vocabulary = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of a word being positive is: 0.16083788706739527 \n",
      "The probability of a word being positive is: 0.2098360655737705 \n",
      "The probability of a word being positive is: 0.6293260473588342\n"
     ]
    }
   ],
   "source": [
    "# Task 4 - Creating the (prior probabilities) total number of yk for k= 'negative', 'positive' and 'neutral' in \n",
    "# the traiting set.\n",
    "\n",
    "class PriorProbabilities:\n",
    "    def __init__(self, tweets):\n",
    "        self.tweets = tweets.airline_sentiment\n",
    "        self.dictionary = {}\n",
    "        self.score = 0\n",
    "        self.final_score = 0\n",
    "    \n",
    "    def dic(self):\n",
    "        for line in self.tweets:\n",
    "            line = line.split()\n",
    "            for word in line:\n",
    "                if word not in self.dictionary:\n",
    "                    self.dictionary[word] = 1\n",
    "                elif word in self.dictionary:\n",
    "                    self.dictionary[word] += 1\n",
    "        return self.dictionary\n",
    "    \n",
    "    def probability(self, x):\n",
    "        self.score = sum(self.dictionary.values())\n",
    "        self.final_score = self.dictionary[x] / self.score\n",
    "        return self.final_score\n",
    "\n",
    "prob = PriorProbabilities(x_train)\n",
    "prob.dic()\n",
    "positive_prob = prob.probability('positive')\n",
    "negative_prob = prob.probability('negative')\n",
    "neutral_prob = prob.probability('neutral')\n",
    "print('The probability of a word being positive is:', positive_prob, '\\nThe probability of a word being positive is:', neutral_prob,\n",
    "      '\\nThe probability of a word being positive is:', negative_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5 (1/2) - Creating several lists based on a word being in a tweet with yk|k = negative/positive/neutral, \n",
    "# which in turn is the likelihood probabilities.\n",
    "\n",
    "negative_list = []\n",
    "positive_list = []\n",
    "neutral_list = []\n",
    "\n",
    "def check_sentiment():\n",
    "    for line in x_train.values:\n",
    "        var = line[0]\n",
    "        var = var.split(' ')\n",
    "        \n",
    "        for word in var:\n",
    "            if word in vocabulary:\n",
    "                if line[1] == 'negative':\n",
    "                    negative_list.append(word)\n",
    "                \n",
    "                if line[1] == 'positive':\n",
    "                    positive_list.append(word)\n",
    "                \n",
    "                if line[1] == 'neutral':\n",
    "                    neutral_list.append(word)\n",
    "        \n",
    "check_sentiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a function to track the amount of times a single word is in each given sentiment (positive, negative, neutral).\n",
    "\n",
    "def iterate(vocabulary):\n",
    "    dictionary = {}\n",
    "    for word in vocabulary:\n",
    "        if word not in dictionary:\n",
    "            dictionary[word] = 1\n",
    "        if word in dictionary:\n",
    "            dictionary[word] += 1\n",
    "            \n",
    "    return dictionary\n",
    " \n",
    "# Task 8 (1/2) - Creating a function which adds all words not currently in a given class with a minimal probability.    \n",
    "\n",
    "def failsafe():\n",
    "    for word in vocabulary:\n",
    "        if word not in new_negative:\n",
    "            new_negative[word] = 1/(len(new_negative) + len(vocabulary) + 1)\n",
    "            \n",
    "        if word not in new_positive:\n",
    "            new_positive[word] = 1/(len(new_positive) + len(vocabulary) + 1)\n",
    "            \n",
    "        if word not in new_neutral:\n",
    "            new_neutral[word] = 1/(len(new_neutral) + len(vocabulary) + 1)\n",
    "            \n",
    "\n",
    "new_negative = iterate(negative_list)\n",
    "new_positive = iterate(positive_list)\n",
    "new_neutral = iterate(neutral_list)\n",
    "failsafe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5 (2/2) - Creating dictionarys to supply the probability of each word belonging to each class.\n",
    "\n",
    "negative_dictionary = {}\n",
    "positive_dictionary = {}\n",
    "neutral_dictionary = {}\n",
    "\n",
    "\n",
    "for word in vocabulary:\n",
    "    if word not in negative_dictionary:\n",
    "        negative_dictionary[word] = new_negative[word] / (new_negative[word] + new_positive[word] + new_neutral[word])\n",
    "\n",
    "    if word not in positive_dictionary:\n",
    "        positive_dictionary[word] = new_positive[word] / (new_negative[word] + new_positive[word] + new_neutral[word])\n",
    "\n",
    "    if word not in neutral_dictionary:\n",
    "        neutral_dictionary[word] = new_neutral[word] / (new_negative[word] + new_positive[word] + new_neutral[word])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 6- Creating a classifier which calculates the probability of each word belongig to each class, then combining every score to give the \n",
    "# full tweet a score of either negative, positive or neutral\n",
    "\n",
    "class Classifier_Score():\n",
    "    def __init__(self, inp):\n",
    "        self.negative_score = 0\n",
    "        self.positive_score = 0\n",
    "        self.neutral_score = 0\n",
    "        self.inp = inp\n",
    "\n",
    "    def classifier(self, fulltweet):\n",
    "        for word in self.inp:\n",
    "            if word in vocabulary:\n",
    "                #Using variables to inplement Bayes theorem.\n",
    "                negative = ((negative_prob * negative_dictionary[word])/(negative_dictionary[word]+positive_dictionary[word]+neutral_dictionary[word]))\n",
    "                positive = ((positive_prob * positive_dictionary[word])/(negative_dictionary[word]+positive_dictionary[word]+neutral_dictionary[word]))    \n",
    "                neutral = ((neutral_prob * neutral_dictionary[word])/(negative_dictionary[word]+positive_dictionary[word]+neutral_dictionary[word]))\n",
    "                \n",
    "                \n",
    "                if max([positive, negative, neutral]) == negative:\n",
    "                    self.negative_score += negative\n",
    "                    \n",
    "                elif max([positive, negative, neutral]) == positive:\n",
    "                    self.positive_score += positive\n",
    "                \n",
    "                elif max([positive, negative, neutral]) == neutral:\n",
    "                    self.neutral_score += neutral\n",
    "            \n",
    "# Task 8 (2/2) - Creating a failsafe for words not currently in the vocabulary.\n",
    "\n",
    "            elif word not in vocabulary:\n",
    "\n",
    "                vocabulary[word] = 0.1\n",
    "                negative_dictionary[word] = 1/(len(negative_dictionary) + len(vocabulary) + 1)\n",
    "                neutral_dictionary[word] = 1/(len(neutral_dictionary) + len(vocabulary) + 1)\n",
    "                positive_dictionary[word] = 1/(len(positive_dictionary) + len(vocabulary) + 1)\n",
    "            \n",
    "        \n",
    "        if max(self.positive_score, self.negative_score, self.neutral_score) == 0:\n",
    "            fulltweet[' '.join(self.inp)] = 'neutral'\n",
    "        elif max(self.positive_score, self.negative_score, self.neutral_score) == self.negative_score:\n",
    "            fulltweet[' '.join(self.inp)] = 'negative'    \n",
    "        elif max(self.positive_score, self.negative_score, self.neutral_score) == self.positive_score:\n",
    "            fulltweet[' '.join(self.inp)] = 'positive'\n",
    "        elif max(self.positive_score, self.negative_score, self.neutral_score) == self.neutral_score:\n",
    "            fulltweet[' '.join(self.inp)] = 'neutral'\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 7 (1/2) - Testing the classifier on the test set.\n",
    "\n",
    "def test_classifier():\n",
    "    test_set = {}\n",
    "    for line in x_test.text:\n",
    "        line = line.split(' ')\n",
    "        node = Classifier_Score(line)\n",
    "        node.classifier(test_set)\n",
    "    \n",
    "    return pd.DataFrame(test_set.items(), \n",
    "                        columns=['text', 'sent_predict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tested = test_classifier()\n",
    "x_test = x_test.reset_index(drop = True)\n",
    "\n",
    "complete_predict = pd.merge(x_tested, x_test, \n",
    "              left_index = True, \n",
    "              right_index = True)\n",
    "\n",
    "complete_predict = complete_predict.drop(['text_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction rate of the Naive Bayes classifier is: 62%\n"
     ]
    }
   ],
   "source": [
    "# Task 7 (2/2) - Calculating the Naive Bayes classifier error rate.\n",
    "\n",
    "score = 0\n",
    "\n",
    "for line in complete_predict.values:\n",
    "    if line[1] == line[2]:\n",
    "        score += 1\n",
    "\n",
    "prediction_rate = round((score / len(complete_predict.values)) * 100)\n",
    "print('Prediction rate of the Naive Bayes classifier is: ' + str(prediction_rate) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 9 - Creating a function to test which class a given input is.\n",
    "\n",
    "def class_tester():\n",
    "    test_dictionary = {}\n",
    "    tweet = input('Please insert your tweet here!')\n",
    "    tweet = tweet.split(' ')\n",
    "    complete_tweet = Classifier_Score(tweet)\n",
    "    complete_tweet.classifier(test_dictionary)\n",
    "    liste = []\n",
    "    count = 0\n",
    "    print(test_dictionary)\n",
    "    \n",
    "# Task 10 - Prints an explination why a tweet is labeled in a certain way.\n",
    "\n",
    "    for fulltweet in test_dictionary:\n",
    "        tweet = fulltweet.split(' ')\n",
    "        for word in tweet:\n",
    "            if vocabulary[word] >= 1:\n",
    "                count += 1\n",
    "            else:\n",
    "                liste.append(word)\n",
    "                \n",
    "                \n",
    "        if count >= 1:\n",
    "            print('The tweet \\'' + str(fulltweet) + '\\' is classified as', \n",
    "                          test_dictionary[fulltweet], 'because by using the Bayes algorithm we can input the prior probabilities of a tweet being', \n",
    "                          test_dictionary[fulltweet], 'then multiply it by the likelihood probabilities of the word in that tweet =', \n",
    "                          test_dictionary[fulltweet], 'and divide it by the evidence that is the probability of the word to exist in the sentence.')\n",
    "        \n",
    "        if len(liste) > 0:\n",
    "            print('\\nThe following word(s)', liste, 'is currently not in the vocabulary.', \n",
    "                  '\\nTo avoid 0 probability, the word(s) has been calculated and added to the vocabulary with a probability of less than 1 occurance.', \n",
    "                  '\\nAnd further calculate the word(s) to being either neutral, negative or positive based on recognized words in the tweet.\\n')\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 11 - Explaining why two tweets are catagorized as they are.\n",
    "def example():\n",
    "    print('The tweet \\'@united @dmb41shows I need this plane to get to buffalo so I can leave tonight.', \n",
    "          'Any progress?\\' is categorized as negative, and also predicted as such.', \n",
    "          'This is because the words: [need, plane, buffalo, leave] are strong negative words in the classifier.', \n",
    "          'The rest of the words are either stopwords or not recognized so they won\\'t impact the classification\\n')\n",
    "\n",
    "    print('The tweet \\'@AmericanAir do you guys have wifi on international flights?\\' is categorized as neutral, but predicted as negative.',\n",
    "         'The reason for the classifier to think that this tweet is negative is because the words: [guys, wifi, international]',\n",
    "         'are al categorized as negative words. However all the remaining words are either stop words or recognized by the vocabulary.',\n",
    "         'Hence why, instead of it realizing that this is actually a neutral tweet, it categorizes it as a negative tweet.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this code to test any text you want!\n",
    "#class_tester()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this code to see why two tweets are either correctly or incorrectly predicted!\n",
    "#example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
